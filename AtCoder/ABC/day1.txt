■人工知能(46)
・K近傍法
k近傍法は、特徴空間における最も近い訓練例に基づいた分類の手法でありパターン認識でよく使われる。
最近傍探索問題の一つ。k近傍法は、インスタンスに基づく学習の一つであり、怠惰学習の一種である。
その関数は局所的な近似に過ぎず、全ての計算は分類時まで後回しにされる。また、回帰分析にも使われる。

・決定木
機械学習の予測モデルであり、ある事項に対する観察結果から、その事項の目標値に関する結論を導く。
内部節点は変数に対応し、子節点への枝はその変数の取り得る値を示す。 
葉は、根からの経路によって表される変数値に対して、目的変数の予測値を表す。
データから決定木を作る機械学習の手法のことを決定木学習という。
その分類に至る過程の解釈が容易であるために、データマイニングで使われる。

・カーネル法
パターン認識において使われる手法の一つで、判別などのアルゴリズムに組み合わせて利用されるものである。
データを高次元の特徴空間に写像することにより、データの集合はユークリッド空間中の点の集合に変換される。
カーネル法の由来であるカーネル関数を用いて、特徴空間における座標の計算を経ずにデータの内積を計算することで、
計算複雑度を抑えつつ内積に基づく解析手法を高次元空間へ拡張する。
よく知られているものに、サポートベクターマシンと組み合わせて利用する方法がある。

・サポートベクタマシン
教師あり学習を用いるパターン認識モデルの一つであり、分類や回帰に適用できる。
線形入力素子を利用して2クラスのパターン識別器を構成する。
訓練サンプルから各データ点との距離が最大となるマージン最大化平面を求めるという基準で線形入力素子のパラメータを学習する。
学習過程はラグランジュの未乗数法とKKT条件を用いることにより最適化問題の一種である凸二次計画問題として定式化される。

・バギング
回帰および分類で使われる機械学習アルゴリズムの安定性と精度を
高めるために設計された機械学習アンサンブルメタアルゴリズム。
学習データの一部のみを使用して学習し最後に結合させることで並列処理が可能になる。
バギングは分散を縮小させ過剰適合を避けることもできる。有名なアルゴリズムとしてフォレストがある。

・ブースティング
教師あり学習を実行するための機械学習のメタアルゴリズムの一種である。
一連の弱い学習機を繰り返し学習させてそれをまとめることで、強い学習機を生成する。
ただし弱い学習とは真の分類と若干の相関を持つ分類器であり、強い分類器とは真の分類と良く相関する分類器である。
有名なアルゴリズムとしてAdaBoostがある。

----------------------------------------------------------------------------

・グラフィカルモデル
グラフが確率変数間の条件付き依存構造を示しているような確率モデルである。
確率モデルの構造を視覚化する簡単な方法であり、そのグラフ構造を調べることで条件付き独立性などのモデルの性質を知ることができる。
また、推論や学習を実行するための複雑な計算をグラフ上の操作として表現することができる。
一般に確率・統計、機械学習などで用いられ、特にマルコフ確率場やベイジアンネットワークで用いられる。

・ベイジアンネットワーク
因果関係を確率により記述するグラフィカルモデルの一つである。
因果的な特徴を有向グラフによるネットワークとして表しその上で確率推論を行うことで、
複雑でかつ不確実な事象の起こりやすさを予測することができる。
有向グラフを用いずに無向グラフで表現する方法はマルコフ確率場と呼ばれる。
言語認識やイメージ認識などで応用される。


・マルコフ確率場
無向グラフで表現されるようなマルコフ性のある確率変数の集合のこと。
確率の依存関係の表現の仕方はベイジアンネットワークと似ているが、
マルコフ確率場は無向で巡回していても構わない。
このことにより、確率の依存関係が巡回している場合の確率構造を表すこともできる。
マルコフ確率場は画像のノイズ除去などに応用される。

・マルコフ連鎖
確率過程の一種であるマルコフ過程のうち、取りうる状態が離散的なものをいう。
マルコフ連鎖は、未来の挙動が現在の値だけで決定され過去の挙動と無関係である。
各時刻において起こる状態変化に関して、マルコフ連鎖は遷移確率が過去の状態によらず、現在の状態のみによる系列である。
マルコフ連鎖は待ち行列理論や強化学習で用いられる。

・マルコフ決定過程
状態が確率的に遷移する動的システムの確率モデルであり状態遷移がマルコフ性を満たすものをいう。
各時刻においてある状態を取り、意思決定者はその状態においての行動を任意に選択する。
そのあと過程はランダムに新しい状態へと遷移し、意思決定者は状態遷移に応じた報酬を得る。
マルコフ決定過程は、不確実性を伴う意思決定のモデリングにおける数学的枠組みとして、
強化学習などの動的計画法が適用される幅広い最適化問題の研究に活用されている。

・TD学習
強化学習の一つであり、TD誤差が0に近くよう評価値を更新していく手法のこと。
TD誤差とはエージェントが行動する前後の評価値の誤差のことである。
評価値とはある行動が将来どのくらい報酬に結びつくかを反映した値である。
ある状態s1でaという行動をすれば報酬を獲得できたとするならば、a(s1)は報酬にありつける可能性の高い行動となる。
TD誤差が0に近づくことで行動前後の評価が一致することになり、局面ごとに最終的な報酬を最大化する行動をすることができるようになる。

・Q学習
Q学習は強化学習手法の方策オフ型TD学習の一つである。
Q学習では実行するルールに対しそのルールの有効性を示すQ値という値を持たせ、エージェントが行動するたびにその値を更新する。
ここでいうルールとは、ある状態とその状態におけるエージェントの行動を対にしたものである。
Q学習では一定の条件のもとで全てのQ値は確率1で最適値に収束するため、局面ごとにQ値の大きな行動が高確率で選ばれるように更新を行うことで最適な状態遷移の学習が行われる。

・強化学習
強化学習とは、ある環境内におけるエージェントが、現在の状態を観測し、取るべき行動を決定する問題を扱う機械学習の一種。
エージェントは行動を選択することで環境から報酬を得る。強化学習は一連の行動を通じて報酬が最も多く得られるような方策を学習する。
代表的な手法としてTD学習やQ学習が知られている。
最も基本的なモデルではここでの環境は、有限状態数のマルコフ決定過程として定式化される。
また、強化学習のアルゴリズムは動的計画法に類似したアルゴリズムである。

・EMアルゴリズム
確率モデルのパラメータを最尤推定する手法の一つであり、観測不能な潜在変数に確率モデルが依存する際に用いられる。
反復法の一種であり、期待値ステップと最大化ステップを交互に繰り返すことで計算が進行する。
Eステップでは現在推定されている潜在変数の分布に基づいてモデルの尤度の期待値を計算する。
MステップではEステップで求まった尤度を最大化するようなパラメータを求める。
このパラメータは次のEステップで潜在変数の分布を決定するために用いられる。
機械学習、音声認識、因子分析などに応用されている。


----------------------------------------------------------------------------
・ベクトル量子化
情報理論における量子化の手法の総称。
通常の量子化は標本化したアナログ信号の各サンプルに対して
最も近い離散値のデジタル符号に置き換えることで行われるのにたいして、
ベクトル量子化は複数のサンプルを取り込みそれをまとめて符号化する。
この複数データをベクトルとして扱うためにベクトル量子化と呼ばれる。
近年ではベクトルデータの次元を落とす方法として画像や音声の非可逆圧縮の作成に使われたりする。

・シグモイド関数

----------------------------------------------------------------------------

・パーセプトロン
人工ニューロンやニューラルネットワークの一種である。
視覚と脳の機能をモデル化したものであり、パターン認識を行う。
シンプルなネットワークでありながら学習能力を持ち、一時ニューラルネットワークブームを巻き起こしたが、
ミンスキーらによって線形分離不能であることが指摘され一時下火となる。
その後変種のものが考案され現在広く使われるディープラーニングの基礎にもなっている。

・活性化関数
ニューラルネットワークにおいて、線形変換をした後に適用する非線形関数または恒等関数である。
数式では下記のように表し、が活性化関数である。
ステップ関数、シグモイド関数、ソフトマックス関数、Reluなどがあるが現在ではReluがよく使われる。
Reluはジェフリーヒントンらによって提案された。

・多層パーセプトロン
順伝播型ニューラルネットワークの一種である。
入力ノードを除けば、個々のノードは非線形の関数を使用するニューロンである。
多層パーセプトロンは、学習のためにバックプロパゲーションと呼ばれる教師あり学習を利用する。
その多層構造と非線形関数が多層パーセプトロンと線形パーセプトロンを区別している。
多層パーセプトロンは画像認識や音声認識に応用される。

・ボルツマンマシン
ジェフリーヒントンらによって開発された確率リカレントニューラルネットワークの一種である。
ボルツマンマシンは、統計的な変動をもちいたホップフィールド・ネットワークの一種と見なすことができる。
しかし、規模の拡大とともに学習が行えなくなるという問題があり、 接続制限を持たないボルツマンマシンは
機械学習や推論のためには実用的であるとは証明されていない。
ボルツマンマシンの応用としてレコメンデーションや組み合わせ最適化問題がある。

・ディープラーニング
多層のニューラルネットワークによる機械学習手法である。
4層以上の深層ニューラルネットは局所最適や勾配消失などの問題により性能も芳しくなかったが、
近年のジェフリーヒントンらによる学習の研究や学習に必要な計算機の能力向上などによって十分学習させられるようになった。
画像認識や音声認識に応用され、関連するモデルが次々に開発されている。

・畳み込みニューラルネットワーク
畳み込みニューラルネットワーク とは、全結合していない順伝播型ニューラルネットワークの一種。
特に2次元の畳込みニューラルネットワークは人間の視覚野のニューロンの結合と似たニューラルネットワークであり、
人間の認知とよく似た学習が行われることが期待される。
結合がスパース（疎）であるため、全結合しているニューラルネットワークに比べて学習が高速である。
2012年にILSVRCでの物体カテゴリ認識で優勝したアルゴリズムも深層畳み込みニューラルネットワークでもある。

・敵対的生成ネットワーク
教師なし学習で使用される機械学習アルゴリズムの一種であり、
生成ネットワークと識別ネットワークの2つのネットワークから構成される。
例えば、画像生成を目的とするならば、生成側がイメージを出力し、識別側がその成否を判定する。
生成側は識別側を欺こうと学習し識別側は正確に識別しようと学習する。
イアングッドフェローらによって発表された。

・オートエンコーダ
機械学習においてニューラルネットワークを使用した次元圧縮のためのアルゴリズム。
3層ニューラルネットワークにおいて、入力層と出力層に同じデータを用いて教師あり学習させてものである。
2006年にイギリス出身のコンピュータ科学者ジェフリーヒントンらが提案した。
線形の次元圧縮としては主成分分析があるが、オートエンコーダではニューラルネットワークを使用するため非線形最適化問題となる。

・確率的勾配降下法
連続最適化問題に対する勾配法の乱択アルゴリズムである。
バッチ学習である最急降下法をオンライン学習に改良したもの。
目的関数の勾配近似を訓練データの一つずつから行うことでパラメータが局所会に陥ることを防ぐことができる。
確率的勾配法は機械学習や深層学習におけるパラメータの最適化でしばしば用いられる。

・バックプロパゲーション
機械学習においてニューラルネットワークを学習させる際に用いられるアルゴリズムである。
訓練データを用いてニューラルネットワークの出力値を求め、期待される出力値との誤差を計算し、これが小さくなるように出力側から入力まで反対向きに誤差を更新して行く。
ネットワーク上の重みについての誤差の傾斜を計算し、これを最小化するように確率的最急降下法などを用いて計算を行う。
バックプロパゲーションの限界として、ネットワーク中の一箇所にでも勾配が消失するとそれ以上学習が進まなくなってしまうため、層が増えると勾配消失を起こす可能性が高まる



----------------------------------------------------------------------------


・ランダムフォレスト
機械学習のアルゴリズムの一種であり、分類・回帰・クラスタリングに用いられる。
決定木を弱学習器とするアンサンブルメソッドであり、ランダムサンプルされた訓練データによって多数の決定木を使用する。
長所として、独立な決定木の並列処理が可能であること、学習や評価が高速なことなどがある。
ランダムフォレストをさらに多層にしたディープフォレストなどの手法も提案されている。


・教師あり/なし学習
教師あり学習：
事前に与えられた訓練データを例題とみなしそれらに対して学習を行う。
典型的なものとして分類問題と回帰問題があり、与えられたデータに対してなんらかの基準を持ってy=f(x)を求めることである。
サポートベクタマシーン、バックプロパゲーションなどが教師あり学習である。

教師なし学習：
出力すべきものがあらかじめ決まっておらず、データの背後に存在する本質的な構造を抽出するために用いられる。
具体例としては、クラスター分析、主成分分析などがある。

・次元の呪い
空間の次元が増えるのに対して問題の算法が指数関数的に増えることである。
例えば単位空間をサンプリングするには100個の点を等間隔でかつ点間の距離を0.01以上にならないようにすれば十分である。
ところが同じようなサンプルを10次元の超立方体で行おうとすると必要な点は10^20になる。
機械学習では、有限この標本から自然の状態を学習しようとする際に、問題を複雑化する。

・主成分分析
相関のある多数の変数から相関のない少数で全体のばらつきを最も表す主成分と呼ばれる変数を合成する多変量解析の一手法。
データの次元を削減するために用いられる。
主成分を与える変換は、第一主成分の分散を最大化し、続く主成分は
それまでに決定した主成分と直交するという拘束条件のもとで分散を最大化するようにして選ばれる。
主成分の分散を最大化することは観測値の変化に対する説明能力を可能な限り主成分に持たせる目的で行われる。

・ビタビアルゴリズム
観測された事象系列を結果として生じる隠された状態の最も尤もらしい並びを探す
動的計画法アルゴリズムの一種であり、隠れマルコフモデルに基づいている。
ある時間tとともにある観測値があるとする。この一連の観測結果からこの観測値を出力した状態系列のうち尤もらしいものはどれであるかを推定するものである。（観測：読書→読書→読書。状態：雨→雨→雨。）
音声認識、自然言語処理、通信経路の誤り検出訂正などに使われている。


・コーパス
言語学において自然言語処理の研究に用いるため自然言語の文章を構造化し大規模に集積したもの。
構造化した文章に品詞などの言語情報を付与している。


・ベイジアンフィルタ

文脈自由文法
形式言語の理論において全生成規則がV→wの形式を持つ形式文法である。
Vは非終端記号でwは終端文字と終端記号で構成される文字列である。
「文脈自由」という用語は前後関係に頼ることなく非終端記号のVをwに置換できるという意味であり、
文脈自由文法によって生成される形式言語を文脈自由文法という。

構文解析
文章などの文字列を自然言語であれば形態素に切り分け、
さらに修飾被修飾などの形態素間の統語的な関係を図式化するなどの手続き。
プログラミング言語であればプログラム中に記述された文が
その言語の使用に適ったものであるかどうかをコンパイラが判別すること。
プログラミング言語などの形式言語の場合は形式文法に従い構文木を得る。

・形態素解析
自然言語のテキストデータから、対象言語の文法や辞書と呼ばれる単語の品詞等の情報に基づき、
形態素（言語で意味を持つ最小単位）の列に分割しそれぞれの形態素の品詞等を判別する作業のこと。
自然言語処理の分野における主要なテーマの一つであり、機会翻訳やかな漢字変換などに応用される。
例えば、「お待ちしております。」を形態素解析した場合には以下のような区分けになる。/お待ち/し/て/おり/ます/。

・チョムスキー標準形
形式言語の理論において、ある文脈自由文法Gのどの生成規則も次のいずれかで表される時のことをいう。
A→BC
A→a
ここで、ABは互いに異なる非終端記号、aは終端記号である。
空列を含まないどのような文脈言語Lに対してもLを生成するチョムスキー標準形の文脈自由文法Gが存在することが知られている。
CYKアルゴリズムなどの効率的なアルゴリズムの基礎となっている。

・正規言語と正規文法
正規文法とは全ての正規言語を記述することのできる形式文法であり、すべて文脈自由文法に包含される。
正規言語とは、有限オートマトンが受理可能な言語であり、正規表現で表すことが可能な言語である。
具体的には、文字集合Σ上の言語の集合が下記によって再帰的に定義される。
・空の言語0
・空文字言語{ε}
・a∈Σであるaについてそれだけを含む集合
・AとBが正規言語の時のA ∪ B、A・B、A*


・フレーム問題
人工知能における重要な難問の一つで、有限の情報処理能力しかないロボットは
現実に起こりうる問題全てに対処することができないことを示すものである。
例えば洞窟の中にある、上に時限爆弾の乗ったバッテリーをロボットにとって来させることを考える。
この場合、①ロボットは爆弾と一緒にバッテリーを運んできてしまうし、
②目的遂行にあたっての副次的事項を考慮させると副次的に発生しうるあらゆることを思考し続けてしまうし、
③目的遂行に無関係なことを考慮しないようにすると目的に無関係なことは何かを無限に思考する。
つまり、思考すべき空間が有限でない限り、無限の可能性に潰え考えざるを得ないということを問題にしている。


・評価関数
コンピュータにゲームなどをプログラムさせる際に状態を評価し数値に変換する関数のこと。
局面の良し悪しを数値化し、それを元に行動を決定する。オセロなどの現実的なゲームでは
単純なアルゴリズムでは測れない要素が複雑に関係し合うために正確な局面の評価はできない。
そのため、行動ごとに枝分かれしていくゲーム木を作り、数手先の局面で評価関数を使用することにより行動を決定する方法が用いられる。

・窓関数
ある有限区間（台）以外で0となる関数である。 ある関数や信号（データ）に窓関数が掛け合わせられると、区間外は0になり、有限区間内だけが残るので、数値解析が容易になる。 窓関数は、スペクトル分析、フィルタ・デザインや、音声圧縮に応用される。 窓関数を単に窓 (window) ともいい、データに窓関数を掛け合わせることを窓を掛ける (windowing) という。実装可能な有限のタップ数を持つフィルタにおいて生じる制約の範囲内で周波数分解能とダイナミックレンジのバランスの調節を行うための関数である。

・ブートストラップ法　
ブートストラップ法は母集団の推定量の性質を、近似分布にしたがって標本化したときの性質を計算することで推定する手法である。
近似分布としては、測定値から求められる経験分布を用いるのが標準的である。また仮説検定に使う場合もある。
仮定される分布が疑わしい場合や、パラメトリックな仮定が不可能ないし非常に複雑な計算を必要とするような場合に、
パラメトリックな仮定に基づく推計の代わりに用いられる。


・交差エントロピー
二つの確率分布の間に定義される尺度であり、符号化方式が真の確率分布pでなく、
ある所定の確率分布qに基づいている場合に取りうる複数の事象の中から一つの事象を特定するために必要となるビット数の平均値を表す。
交差エントロピーの最小化は最適化問題と希少事象の予測によく使われる技法である。



・ソフトマックス関数
ニューラルネットワークにおける活性化関数の一つで、多値分類をする時のそのクラスへの分類される確率を出力する。
yi=exp(ai)/Σexp(aj)の数式で示される。ここでyiは出力層のi番目のユニットの出力。Dは出力層のユニット数である。
分母に和の式を導入することで出力層の全てのユニットの出力の和をとると1になる。結果的にそのネットワークの出力があるクラスに属する確率を表すことができる。

ーーーーーー〜ーーー


(38)

■統計・情報理論(21)
・中心極限定理
確率論統計学における極限定理の一つである。
「母集団の分布がどんなものであってもn個の標本平均の確率分布はnが十分に大きければ
平均μ、分散σ^2/nの正規分布に近似できる」という定理である。
例えば、世論調査における必要サンプルサイズの算出や選挙の出口調査による当選結果の予測に使われる。


・最尤推定
統計学において、与えられたデータからそれが従う確率分布の母数を点推定する方法である。
例えばある確率分布関数fと分布の母数θのわかっている離散確率分布Dが与えられたとする。
そこからn個の標本X1X2..Xnを取り出すことを考えた時、データが分布Dに寄ることがわかっても母数θがわからない場合、
標本からθを見積もることができる。最尤法は母数θの一番尤もらしい値を探す方法である。

・ベイズ推定
ベイズ確率の考え方に基づき、観測事象から推定したい事柄を確率的な意味で推論することを指す。
ベイズの定理が基本的な方法論として用いられ、名前の由来となっている。
事象Bのベイズ確率について、
P(A)：事象Bが起きる前の事象Aの確率
P(A|B)事象Bが起きた後での事象Aの確率とする。
この時、ベイズの定理によってP(A|B)=P(B|A)P(A)/P(B)で表される。
事象Aに関するあるデータが得られたとすると、それを反映し、尤度P(B|A)の乗算によって事象Bの確率は事前確率から事後確率へと更新される。
現在ではコンピュータを用いた方法の発展によりベイズ推定の方法も発展し、スパムメールを識別するための応用が進んでいる。

・赤池情報量基準
統計モデルの良さを評価するための指標である。
AICは、「モデルの複雑さと、データとの適合度とのバランスを取る」ために使用される。
ある測定データを統計的に説明するモデルを作成することを考える。
この場合、パラメータの数や次数を増やせば増やすほど、その測定データとの適合度を高めることができるが、過剰適合もしやすくなる。これを避けるためにどの程度パラメータ数を抑えるべきかに対しての会を与えることができる。

・隠れマルコフモデル
確率モデルの一つで、観測されない状態をもつマルコフ過程である。
同じマルコフ過程でもマルコフ連鎖では、状態が直接観測可能で状態の遷移確率がパラメータであるのに対して、
隠れマルコフモデルにおいては状態は直接観測されず、モデルの状態による確率分布に基づいた出力のみが観測される。
隠れマルコフモデルは、音声認識、バイフォインフォマティクス、形態素解析など時系列のパターン認識に応用されている。

・擬似乱数
乱数列のように見えるが、実際には確定的な計算によって求めている擬似乱数列による乱数。
擬似乱数列を生成する機器を擬似乱数列生成器、生成アルゴリズムを擬似乱数列生成法と呼ぶ。
真の乱数列は本来、規則性も再現性もないものであるため、本来は確定的な計算によって求めることはできない。
一方、擬似乱数列は確定的な計算によって作るので、その数列は確定的であるうえ、生成法と内部状態が既知であれば、予測可能でもある。
シミュレーション実験や暗号などに利用されている。

・カルバックライブラー情報量
確率論や情報理論における二つの確率分布の差異を図る尺度である。
真の確率分布pとそれ以外の任意の確率分布qに対するカルバックライブラー情報量が計算されることが多い。
例えば、pは観測値や正確に求められた確率分布などを表し、qは理論値や予測値を表す。
カルバックライブラー情報量は下記のように表される。交差エントロピーなどに使われる。＿

・ニュートン法
数値解析の分野においてニュートン法は方程式を数値計算によって解くための反復法による球根アルゴリズムの一つである。
まずはじめに予想される真の解に近いと思われる値を一つとる。次にそのグラフの接線を考えそのx切片を計算する。
このx切片の値は予想される真の解に近いものとなるのが一般的である。
以後この値に対してグラフの接戦を考え同じ操作を繰り返すことで解析的に解けない方程式の近似解を与える。

・基底関数
基底関数とは函数空間の基底ベクトルのことである。
すなわち対象となる空間に属する全ての関数はこの基底関数の線型結合で表される。
例えば実数値函数のフーリエ変換ではコサイン函数もしくはサイン関数が基底関数として用いられる。

順運動学
ロボットの各関節の変位量が与えられた時、ロボットの手先の位置と方向が

・逆運動学
・決定理論

・相互情報量
情報理論において2つの確率変数の相互依存の尺度を表す量である。
最も典型的な相互情報量の物理単位はビットであり、2を底とする対数が使われることが多い。
XとYが独立な場合の同時分布と実際の同時分布の距離を示す量である。
応用例の多くではその相互情報量を最大化し条件付きエントロピーを最小化させる方向で使われており、例えば機械学習における特徴選択や特徴変換の尺度として相互情報量が使われてきた。


・フィッシャー情報量
フィッシャー情報量は確率変数がパラメータに関して持つ情報量のことである。
統計学者のロナルドフィッシャーにちなんで命名された。
θを母数としXを確率密度がf(x|θ)で表される確率変数とした時、
尤度関数L(θ|x)=f(x|θ)で定義され、スコア関数は対数尤度関数の微分により定義される。
この時、フィッシャー情報量L(θ)はスコア関数の二次のモーメントにより定義される。



■制御(11)
・カルマンフィルタ
カルマンフィルタとは、誤差のある離散的な観測値から時間変化するシステムの現在の状態を推定する手法。
システムの現在の観測値と1ステップ前の推定値から、システムの現在の状態の推定値と1ステップ先の予測値を与える反復型の予測を行う。
カルマンフィルタは各ステップごとに予測と更新の二つを行う。
予測では前ステップの推定値から現在の推定状態を計算し、更新では現在の観測値を利用して推定値を補正してより正確な値に近づける。
例えばカーナビでは機器内蔵の加速度計や人工衛星からの誤差のある情報を統合して自動車の位置を推定するのに応用されている。

・PWM制御
PWMとは、半導体を使った電力を制御する方式の１つです。
オンとオフの繰り返しスイッチングを行い、出力される電力を制御します。
一定電圧の入力から、パルス列のオンとオフの一定周期を作り、オンの時間幅を変化させる電力制御方式をＰＷＭと呼びます。
早い周期でスイッチングを行うことで、オンのパルス幅に比例した任意の電圧が得られます。
優れた制御性と、高効率が特長で、インバータ回路で広く使われている技術です。

・PID制御
制御工学におけるフィードバック制御の一種であり、入力値の制御を出力値と目標値の
偏差、積分、微分の3つの要素によって行う方法のことである。
制御理論の一分野をなす古典制御の枠組みで体系化されたもので長い歴史を持っている。
フィードバック制御の基礎ともなっており、産業界では主力の制御手法である。

・ラプラス変換
関数解析学において積分で定義される関数空間の間の写像の一種。
ラプラス変換によってある種の微分積分は積などの台数的な演算に置き換わるため、
制御工学などにおいて時間領域の関数を別の領域の関数に変換することにより、
計算方法の見通しをよくするための数学的な道具として用いられている。



■信号
・ウェーブレット変換
基底関数としてウェーブレット関数を用いた周波数解析の手法のひとつ。
フーリエ変換によって周波数特性を求める際に失われる時間領域の情報を残すことが可能。
基底関数の拡大拡小を行うことでフーリエ変換では解析の難しい広い周波数領域の解析が可能である。
」フーリエ変換ではNをデータのサイズとするとO(NlogN)のオーダーで計算量が増えるが、
ウェーブレット変換ではO(N）の計算量でできる｡信号解析や量子力学の分野に応用されている。

・ベクトル量子化
情報理論における量子化の手法の総称。
通常の量子化は標本化したアナログ信号の各サンプルに対して最も近い離散値のデジタル符号に置き換えることで行われるのにたいして、ベクトル量子化は複数のサンプルを取り込みそれをまとめて符号化する。
この複数データをベクトルとして扱うためにベクトル量子化と呼ばれる。
近年ではベクトルデータの次数を落とす方法として画像や音声の非可逆圧縮の作成に使われたりする。

・ケプストラム
音のスペクトルを信号とみなしてフーリエ変換した結果である。
複素ケプストラムは最初のスペクトルの振幅と位相に関する情報を保持しており、信号の再構築が可能である。
実数ケプストラムはスペクトルの振幅に関する情報しか保持しない。
ケプストラムは本来自身や爆弾の爆発を原因とする地震生反響の特性を調べるために考案された。
レーダー信号の反射を解析するのにも使われてきた。

・サンプリング周波数変換
サンプリングされた信号に対するリサンプリングの1つで、あるサンプリング周波数で
サンプリングされた信号を別のサンプリング周波数でサンプリングされた信号に変換する処理である。
通常はデジタル信号間の変換だが、サンプリングされていればアナログ信号でもかまわない。
高速フーリエ変換法ではサンプル数Nの原信号に対して高速フーリエ変換と逆変換を行うことでサンプル周波数の変換を行う。


・周波数スペクトル
通常の信号波形は，多数の異なった正弦波が合成されたものと見ることができる。
このとき周波数の関数として，各正弦波の周波数成分の振幅，または振幅および
位相を複素数によって表したものを周波数スペクトルという。
複素数の絶対値がその周波数の正弦波の振幅を表し，偏角が位相を表す。

今68





